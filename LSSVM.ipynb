{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Least-Squares Support Vector machine</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "1. [Introduction](#introduction)\n",
    "\n",
    "2. [LSSVM CPU implementation](#lssvm_cpu)\n",
    "    \n",
    "3. [LSSVM GPU implementation](#lssvm_gpu)\n",
    "\n",
    "4. [Discussing performance](#discussing_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction <a class=\"anchor\" id=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Least-Squares Support Vector Machine (LSSVM) is a variation of the original Support Vector Machine (SVM) in which we have a slight change in the objective and restriction functions that results in a big simplification of the optimization problem.\n",
    "\n",
    "First, let's see the optimization problem of an SVM:\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "    minimize && f_o(\\vec{w},\\vec{\\xi})=\\frac{1}{2} \\vec{w}^T\\vec{w} + C \\sum_{i=1}^{n} \\xi_i &&\\\\\n",
    "    s.t. && d_i(\\vec{w}^T\\vec{x}_i+b)\\geq 1 - \\xi_i, && i = 1,..., n \\\\\n",
    "         && \\xi_i \\geq 0,                            && i = 1,..., n\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In this case, we have a set of inequality restrictions and when solving the optimization problem by it's dual we find a discriminative function, adding the kernel trick, of the type:\n",
    "\n",
    "\n",
    "$$ f(\\vec{x}) = sign \\ \\Big( \\sum_{i=1}^{n} \\alpha_i^o d_i K(\\vec{x}_i,\\vec{x}) + b_o \\Big) $$\n",
    "\n",
    "Where $\\alpha_i^o$ and $b_o$ denote optimum values. Giving enough regularization (smaller values of $C$) we get a lot of $\\alpha_i^o$ nulls, resulting in a sparse model in which we only need to save the pairs $(\\vec{x}_i,d_i)$ which have the optimum dual variable not null. The vectors $\\vec{x}_i$ with not null $\\alpha_i^o$ are known as support vectors (SV).\n",
    "\n",
    "\n",
    "\n",
    "In the LSSVM case, we change the inequality restrictions to equality restrictions. As the $\\xi_i$ may be negative we square its values in the objective function:\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "    minimize && f_o(\\vec{w},\\vec{\\xi})=\\frac{1}{2} \\vec{w}^T\\vec{w} + \\gamma \\frac{1}{2}\\sum_{i=1}^{n} \\xi_i^2 &&\\\\\n",
    "    s.t. && d_i(\\vec{w}^T\\vec{x}_i+b) = 1 - \\xi_i, && i = 1,..., n\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "The dual of this optimization problem results in a system of linear equations, a set of Karush-Khun-Tucker (KKT) equations:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "    0 & \\vec{d}^T \\\\\n",
    "    \\vec{d} & \\Omega + \\gamma^{-1} I \n",
    "\\end{bmatrix}\n",
    "\\\n",
    "\\begin{bmatrix} \n",
    "    b  \\\\\n",
    "    \\vec{\\alpha}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "    0 \\\\\n",
    "    \\vec{1}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Where, with the kernel trick, &nbsp; $\\Omega_{i,j} = d_i d_j K(\\vec{x}_i,\\vec{x}_j)$,  &nbsp;  $\\vec{d} = [d_1 \\ d_2 \\ ... \\ d_n]^T$, &nbsp; $\\vec{\\alpha} = [\\alpha_1 \\ \\alpha_2 \\ ... \\ \\alpha_n]^T$ &nbsp;  e &nbsp; $\\vec{1} = [1 \\ 1 \\ ... \\ 1]^T$.\n",
    "\n",
    "The discriminative function of the LSSVM has the same form of the SVM but the $\\alpha_i^o$ aren't usually null, resulting in a bigger model. The big advantage of the LSSVM is in finding it's parameters, which is reduced to solving the linear system of the type:\n",
    "\n",
    "$$ A\\vec{x} = \\vec{b} $$\n",
    "\n",
    "A well-known solution of the linear system is when we minimize the square of the residues, that can be written as the optimization problem:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    minimize && f_o(\\vec{x})=\\frac{1}{2}||A\\vec{x} - \\vec{b}||^2\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "And have the analytical solution:\n",
    "\n",
    "$$ \\vec{x} = A^{\\dagger} \\vec{b} $$\n",
    "\n",
    "Where $A^{\\dagger}$ is the pseudo-inverse defined as:\n",
    "\n",
    "$$ A^{\\dagger} = (A^T A)^{-1} A^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  Features.shape:   # of classes:\n",
      "vc2c      (310, 6)          2\n",
      "vc3c      (310, 6)          3\n",
      "wf24f     (5456, 24)        4\n",
      "wf4f      (5456, 4)         4\n",
      "wf2f      (5456, 2)         4\n",
      "pk        (195, 22)         2\n"
     ]
    }
   ],
   "source": [
    "%run -i 'load_dataset.py' # loading dataset\n",
    "%run -i 'aux_func.py'     # loading auxilary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LSSVM CPU implementation <a class=\"anchor\" id=\"lssvm_cpu\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import dot, exp\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "class LSSVM:\n",
    "    'Class that implements the Least-Squares Support Vector Machine.'\n",
    "    \n",
    "    def __init__(self, gamma=1, kernel='rbf', **kernel_params): \n",
    "        self.gamma = gamma\n",
    "        \n",
    "        self.x        = None\n",
    "        self.y        = None\n",
    "        self.y_labels = None\n",
    "        \n",
    "        # model params\n",
    "        self.alpha = None\n",
    "        self.b     = None\n",
    "        \n",
    "        self.kernel = LSSVM.get_kernel(kernel, **kernel_params)\n",
    "        \n",
    "           \n",
    "    @staticmethod\n",
    "    def get_kernel(name, **params):\n",
    "        \n",
    "        def linear(x_i, x_j):                           \n",
    "            return dot(x_i, x_j.T)\n",
    "        \n",
    "        def poly(x_i, x_j, d=params.get('d',3)):        \n",
    "            return ( dot(x_i, x_j.T) + 1 )**d\n",
    "        \n",
    "        def rbf(x_i, x_j, sigma=params.get('sigma',1)):\n",
    "            if x_i.ndim==x_i.ndim and x_i.ndim==2: # both matrices\n",
    "                return exp( -cdist(x_i,x_j)**2 / sigma**2 )\n",
    "            \n",
    "            else: # both vectors or a vector and a matrix\n",
    "                return exp( -( dot(x_i,x_i.T) + dot(x_j,x_j.T)- 2*dot(x_i,x_j) ) / sigma**2 )\n",
    "#             temp = x_i.T - X\n",
    "#             return exp( -dot(temp.temp) / sigma**2 )\n",
    "                \n",
    "        kernels = {'linear': linear, 'poly': poly, 'rbf': rbf}\n",
    "                \n",
    "        if kernels.get(name) is None: \n",
    "            raise KeyError(\"Kernel '{}' is not defined, try one in the list: {}.\".format(\n",
    "                name, list(kernels.keys())))\n",
    "        else: return kernels[name]\n",
    "        \n",
    "    \n",
    "    def opt_params(self, X, y_values):\n",
    "        sigma = np.multiply( y_values*y_values.T, self.kernel(X,X) )\n",
    "\n",
    "        A_cross = np.linalg.pinv(np.block([\n",
    "            [0,                           y_values.T                   ],\n",
    "            [y_values,   sigma + self.gamma**-1 * np.eye(len(y_values))]\n",
    "        ]))\n",
    "\n",
    "        B = np.array([0]+[1]*len(y_values))\n",
    "\n",
    "        solution = dot(A_cross, B)\n",
    "        b     = solution[0]\n",
    "        alpha = solution[1:]\n",
    "        \n",
    "        return (b, alpha)\n",
    "            \n",
    "    \n",
    "    def fit(self, X, Y, verboses=0):\n",
    "        self.x = X\n",
    "        self.y = Y\n",
    "        self.y_labels = np.unique(Y, axis=0)\n",
    "        \n",
    "        if len(self.y_labels)==2: # binary classification\n",
    "            # converting to -1/+1\n",
    "            y_values = np.where(\n",
    "                (Y == self.y_labels[0]).all(axis=1)\n",
    "                ,-1,+1)[:,np.newaxis] # making it a column vector\n",
    "            \n",
    "            self.b, self.alpha = self.opt_params(X, y_values)\n",
    "        \n",
    "        else: # multiclass classification\n",
    "              # ONE-VS-ALL APPROACH\n",
    "            n_classes = len(self.y_labels)\n",
    "            self.b     = np.zeros(n_classes)\n",
    "            self.alpha = np.zeros((n_classes, len(Y)))\n",
    "            for i in range(n_classes):\n",
    "                # converting to +1 for the desired class and -1 for all other classes\n",
    "                y_values = np.where(\n",
    "                    (Y == self.y_labels[i]).all(axis=1)\n",
    "                    ,+1,-1)[:,np.newaxis] # making it a column vector\n",
    "  \n",
    "                self.b[i], self.alpha[i] = self.opt_params(X, y_values)\n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "        K = self.kernel(self.x, X)\n",
    "        \n",
    "        if len(self.y_labels)==2: # binary classification\n",
    "            y_values = np.where(\n",
    "                (self.y == self.y_labels[0]).all(axis=1),\n",
    "                -1,+1)[:,np.newaxis] # making it a column vector\n",
    "\n",
    "            Y = np.sign( dot( np.multiply(self.alpha, y_values.flatten()), K ) + self.b)\n",
    "            \n",
    "            y_pred_labels = np.where(Y==-1, self.y_labels[0], \n",
    "                                     self.y_labels[1])\n",
    "        \n",
    "        else: # multiclass classification, ONE-VS-ALL APPROACH\n",
    "            Y = np.zeros((len(self.y_labels), len(X)))\n",
    "            for i in range(len(self.y_labels)):\n",
    "                y_values = np.where(\n",
    "                    (self.y == self.y_labels[i]).all(axis=1),\n",
    "                    +1, -1)[:,np.newaxis] # making it a column vector\n",
    "                Y[i] = dot( np.multiply(self.alpha[i], y_values.flatten()), K ) + self.b[i] # no sign function applied\n",
    "            \n",
    "            predictions = np.argmax(Y, axis=0)\n",
    "            y_pred_labels = np.array([self.y_labels[i] for i in predictions])\n",
    "            \n",
    "        return y_pred_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a single test in all data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vc2c\n",
      "linear kernel\n",
      "acc_test =  0.8258064516129032\n",
      "poly kernel\n",
      "acc_test =  0.8387096774193549\n",
      "rbf kernel\n",
      "acc_test =  0.8258064516129032\n",
      "\n",
      " #################################################################################################### \n",
      "\n",
      "vc3c\n",
      "linear kernel\n",
      "acc_test =  0.7354838709677419\n",
      "poly kernel\n",
      "acc_test =  0.7677419354838709\n",
      "rbf kernel\n",
      "acc_test =  0.7870967741935484\n",
      "\n",
      " #################################################################################################### \n",
      "\n",
      "wf24f\n",
      "linear kernel\n",
      "acc_test =  0.6502932551319648\n",
      "poly kernel\n",
      "acc_test =  0.8680351906158358\n",
      "rbf kernel\n",
      "acc_test =  0.8830645161290323\n",
      "\n",
      " #################################################################################################### \n",
      "\n",
      "wf4f\n",
      "linear kernel\n",
      "acc_test =  0.655791788856305\n",
      "poly kernel\n",
      "acc_test =  0.7096774193548387\n",
      "rbf kernel\n",
      "acc_test =  0.7291055718475073\n",
      "\n",
      " #################################################################################################### \n",
      "\n",
      "wf2f\n",
      "linear kernel\n",
      "acc_test =  0.6279325513196481\n",
      "poly kernel\n",
      "acc_test =  0.6719208211143695\n",
      "rbf kernel\n",
      "acc_test =  0.6876832844574781\n",
      "\n",
      " #################################################################################################### \n",
      "\n",
      "pk\n",
      "linear kernel\n",
      "acc_test =  0.8673469387755102\n",
      "poly kernel\n",
      "acc_test =  0.8877551020408163\n",
      "rbf kernel\n",
      "acc_test =  0.8775510204081632\n",
      "\n",
      " #################################################################################################### \n",
      "\n",
      "CPU times: user 47min 19s, sys: 9min 52s, total: 57min 12s\n",
      "Wall time: 8min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    print(dataset_name)\n",
    "\n",
    "    X = datasets[dataset_name]['features'].values\n",
    "    Y = datasets[dataset_name]['labels'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5)  # Train/Test split\n",
    "    X_tr_norm, X_ts_norm = scale_feat(X_train, X_test, scaleType='min-max') # scaling features\n",
    "    \n",
    "    print('linear kernel')\n",
    "    lssvm = LSSVM(gamma=1, kernel='linear')\n",
    "    lssvm.fit(X_tr_norm, y_train)\n",
    "    print('acc_test = ', accuracy_score(dummie_to_multilabel(y_test), \n",
    "                         dummie_to_multilabel(lssvm.predict(X_ts_norm))))\n",
    "    \n",
    "    print('poly kernel')\n",
    "    lssvm = LSSVM(gamma=1, kernel='poly', d=2)\n",
    "    lssvm.fit(X_tr_norm, y_train)\n",
    "    print('acc_test = ',accuracy_score(dummie_to_multilabel(y_test), \n",
    "                         dummie_to_multilabel(lssvm.predict(X_ts_norm))))\n",
    "    \n",
    "    print('rbf kernel')\n",
    "    lssvm = LSSVM(gamma=1, kernel='rbf', sigma=1)\n",
    "    lssvm.fit(X_tr_norm, y_train)\n",
    "    print('acc_test = ',accuracy_score(dummie_to_multilabel(y_test), \n",
    "                         dummie_to_multilabel(lssvm.predict(X_ts_norm))))\n",
    "    \n",
    "    print('\\n','#'*100,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LSSVM GPU implementation <a class=\"anchor\" id=\"lssvm_gpu\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation uses `PyTorch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class LSSVM_GPU:\n",
    "    'Class that implements the Least-Squares Support Vector Machine on GPU.'\n",
    "    \n",
    "    def __init__(self, gamma=1, kernel='rbf', **kernel_params): \n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        \n",
    "        self.x        = None\n",
    "        self.y        = None\n",
    "        self.y_labels = None\n",
    "        \n",
    "        # model params\n",
    "        self.alpha = None\n",
    "        self.b     = None\n",
    "        \n",
    "        self.kernel = LSSVM_GPU.get_kernel(kernel, **kernel_params) # saving kernel function\n",
    "        \n",
    "           \n",
    "    @staticmethod\n",
    "    def get_kernel(name, **params):\n",
    "        \n",
    "        def linear(x_i, x_j):                           \n",
    "            return torch.mm(x_i, torch.t(x_j))\n",
    "        \n",
    "        def poly(x_i, x_j, d=params.get('d',3)):        \n",
    "            return ( torch.mm(x_i, torch.t(x_j)) + 1 )**d\n",
    "        \n",
    "        def rbf(x_i, x_j, sigma=params.get('sigma',1)):\n",
    "            if x_i.ndim==x_i.ndim and x_i.ndim==2: # both matrices\n",
    "                return torch.exp( -torch.cdist(x_i,x_j)**2 / sigma**2 )\n",
    "            \n",
    "            else: # both vectors or a vector and a matrix\n",
    "                return torch.exp( -( torch.dot(x_i,torch.t(x_i)) + torch.dot(x_j,torch.t(x_j))- 2*torch.dot(x_i,x_j) ) \n",
    "                                 / sigma**2 )\n",
    "#             temp = x_i.T - X\n",
    "#             return exp( -dot(temp.temp) / sigma**2 )\n",
    "                \n",
    "        kernels = {'linear': linear, 'poly': poly, 'rbf': rbf}\n",
    "                \n",
    "        if kernels.get(name) is None: \n",
    "            raise KeyError(\"Kernel '{}' is not defined, try one in the list: {}.\".format(\n",
    "                name, list(kernels.keys())))\n",
    "        else: return kernels[name]\n",
    "        \n",
    "    \n",
    "    def opt_params(self, X, y_values):\n",
    "        sigma = ( torch.mm(y_values, torch.t(y_values)) ) * self.kernel(X,X)\n",
    "\n",
    "        A_cross = torch.pinverse(torch.cat(( \n",
    "            # block matrix\n",
    "            torch.cat(( torch.tensor(0, dtype=X.dtype, device=self.device).view(1,1),\n",
    "                        torch.t(y_values)\n",
    "                      ),dim=1),\n",
    "            torch.cat(( y_values, \n",
    "                        sigma + self.gamma**-1 * torch.eye(len(y_values), dtype=X.dtype, device=self.device) \n",
    "                      ),dim=1)\n",
    "        ),dim=0))\n",
    "\n",
    "        B = torch.tensor([0]+[1]*len(y_values), dtype=X.dtype, device=self.device).view(-1,1)\n",
    "\n",
    "        solution = torch.mm(A_cross, B)\n",
    "        b     = solution[0]\n",
    "        alpha = solution[1:].view(-1) # 1D array form\n",
    "        \n",
    "        return (b, alpha)\n",
    "            \n",
    "    \n",
    "    def fit(self, X, Y, verboses=0):\n",
    "        # converting to tensors and passing to GPU\n",
    "        X = torch.from_numpy(X).to(self.device)\n",
    "        Y = torch.from_numpy(Y).to(self.device)\n",
    "        self.x = X\n",
    "        self.y = Y\n",
    "        self.y_labels = torch.unique(Y, dim=0)\n",
    "        \n",
    "        if len(self.y_labels)==2: # binary classification\n",
    "            # converting to -1/+1\n",
    "            y_values = torch.where(\n",
    "                (Y == self.y_labels[0]).all(axis=1)\n",
    "                ,torch.tensor(-1, dtype=X.dtype, device=self.device)\n",
    "                ,torch.tensor(+1, dtype=X.dtype, device=self.device)\n",
    "            ).view(-1,1) # making it a column vector\n",
    "            \n",
    "            self.b, self.alpha = self.opt_params(X, y_values)\n",
    "        \n",
    "        else: # multiclass classification\n",
    "              # ONE-VS-ALL APPROACH\n",
    "            n_classes = len(self.y_labels)\n",
    "            self.b     = torch.empty(n_classes,         dtype=X.dtype, device=self.device)\n",
    "            self.alpha = torch.empty(n_classes, len(Y), dtype=X.dtype, device=self.device)\n",
    "            for i in range(n_classes):\n",
    "                # converting to +1 for the desired class and -1 for all other classes\n",
    "                y_values = torch.where(\n",
    "                    (Y == self.y_labels[i]).all(axis=1)\n",
    "                    ,torch.tensor(+1, dtype=X.dtype, device=self.device)\n",
    "                    ,torch.tensor(-1, dtype=X.dtype, device=self.device)\n",
    "                ).view(-1,1) # making it a column vector\n",
    "                  \n",
    "                self.b[i], self.alpha[i] = self.opt_params(X, y_values)\n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X = torch.from_numpy(X).to(self.device)\n",
    "        K = self.kernel(self.x, X)\n",
    "        \n",
    "        if len(self.y_labels)==2: # binary classification\n",
    "            y_values = torch.where(\n",
    "                (self.y == self.y_labels[0]).all(axis=1)\n",
    "                ,torch.tensor(-1, dtype=X.dtype, device=self.device)\n",
    "                ,torch.tensor(+1, dtype=X.dtype, device=self.device)\n",
    "            )\n",
    "            \n",
    "            Y = torch.sign( torch.mm( (self.alpha*y_values).view(1,-1), K ) + self.b)\n",
    "            \n",
    "            y_pred_labels = torch.where(Y==-1,        self.y_labels[0],\n",
    "                                        self.y_labels[1]\n",
    "                                       ).view(-1) # convert to flat array\n",
    "        \n",
    "        else: # multiclass classification, ONE-VS-ALL APPROACH\n",
    "            Y = torch.empty((len(self.y_labels), len(X)), dtype=X.dtype, device=self.device)\n",
    "            for i in range(len(self.y_labels)):\n",
    "                y_values = torch.where(\n",
    "                    (self.y == self.y_labels[i]).all(axis=1)\n",
    "                    ,torch.tensor(+1, dtype=X.dtype, device=self.device)\n",
    "                    ,torch.tensor(-1, dtype=X.dtype, device=self.device)\n",
    "                )\n",
    "\n",
    "                Y[i] = torch.mm( (self.alpha[i]*y_values).view(1,-1), K ) + self.b[i] # no sign function applied\n",
    "            \n",
    "            predictions = torch.argmax(Y, axis=0)\n",
    "            y_pred_labels = torch.stack([self.y_labels[i] for i in predictions])\n",
    "            \n",
    "        return y_pred_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a single test in all data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vc2c\n",
      "linear kernel\n",
      "acc_test =  0.8258064516129032\n",
      "poly kernel\n",
      "acc_test =  0.8580645161290322\n",
      "rbf kernel\n",
      "acc_test =  0.8709677419354839\n",
      "\n",
      " #################################################################################################### \n",
      "\n",
      "vc3c\n",
      "linear kernel\n",
      "acc_test =  0.8580645161290322\n",
      "poly kernel\n",
      "acc_test =  0.8387096774193549\n",
      "rbf kernel\n",
      "acc_test =  0.8387096774193549\n",
      "\n",
      " #################################################################################################### \n",
      "\n",
      "wf24f\n",
      "linear kernel\n",
      "acc_test =  0.6543255131964809\n",
      "poly kernel\n",
      "acc_test =  0.8779325513196481\n",
      "rbf kernel\n",
      "acc_test =  0.8947947214076246\n",
      "\n",
      " #################################################################################################### \n",
      "\n",
      "wf4f\n",
      "linear kernel\n",
      "acc_test =  0.6429618768328446\n",
      "poly kernel\n",
      "acc_test =  0.7111436950146628\n",
      "rbf kernel\n",
      "acc_test =  0.7415689149560117\n",
      "\n",
      " #################################################################################################### \n",
      "\n",
      "wf2f\n",
      "linear kernel\n",
      "acc_test =  0.623900293255132\n",
      "poly kernel\n",
      "acc_test =  0.6704545454545454\n",
      "rbf kernel\n",
      "acc_test =  0.6909824046920822\n",
      "\n",
      " #################################################################################################### \n",
      "\n",
      "pk\n",
      "linear kernel\n",
      "acc_test =  0.8571428571428571\n",
      "poly kernel\n",
      "acc_test =  0.8673469387755102\n",
      "rbf kernel\n",
      "acc_test =  0.8571428571428571\n",
      "\n",
      " #################################################################################################### \n",
      "\n",
      "CPU times: user 12min 1s, sys: 1min 22s, total: 13min 24s\n",
      "Wall time: 6min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_size = 0.5\n",
    "for dataset_name in datasets:\n",
    "    print(dataset_name)\n",
    "\n",
    "    X = datasets[dataset_name]['features'].values\n",
    "    Y = datasets[dataset_name]['labels'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,train_size=train_size)  # Train/Test split\n",
    "    X_tr_norm, X_ts_norm = scale_feat(X_train, X_test, scaleType='min-max') # scaling features\n",
    "    \n",
    "    print('linear kernel')\n",
    "    lssvm = LSSVM_GPU(gamma=1, kernel='linear')\n",
    "    lssvm.fit(X_tr_norm, y_train)\n",
    "    print('acc_test = ', accuracy_score(dummie_to_multilabel(y_test), \n",
    "                         dummie_to_multilabel(lssvm.predict(X_ts_norm).cpu().numpy())))\n",
    "    \n",
    "    print('poly kernel')\n",
    "    lssvm = LSSVM_GPU(gamma=1, kernel='poly', d=2)\n",
    "    lssvm.fit(X_tr_norm, y_train)\n",
    "    print('acc_test = ',accuracy_score(dummie_to_multilabel(y_test), \n",
    "                         dummie_to_multilabel(lssvm.predict(X_ts_norm).cpu().numpy())))\n",
    "    \n",
    "    print('rbf kernel')\n",
    "    lssvm = LSSVM_GPU(gamma=1, kernel='rbf', sigma=1)\n",
    "    lssvm.fit(X_tr_norm, y_train)\n",
    "    print('acc_test = ',accuracy_score(dummie_to_multilabel(y_test), \n",
    "                         dummie_to_multilabel(lssvm.predict(X_ts_norm).cpu().numpy())))\n",
    "    \n",
    "    print('\\n','#'*100,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Discussing performance <a class=\"anchor\" id=\"discussing_performance\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below was used to evaluate processing time in several data sets and using different kernels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1/18 at 2019-08-13 21:53:24.580535.\n",
      "Done 2/18 at 2019-08-13 21:53:25.403790.\n",
      "Done 3/18 at 2019-08-13 21:53:27.114317.\n",
      "Done 4/18 at 2019-08-13 21:53:30.465400.\n",
      "Done 5/18 at 2019-08-13 21:53:33.482345.\n",
      "Done 6/18 at 2019-08-13 21:53:36.818694.\n",
      "Done 7/18 at 2019-08-13 22:20:52.139768.\n",
      "Done 8/18 at 2019-08-13 22:54:52.164808.\n",
      "Done 9/18 at 2019-08-13 23:29:40.950704.\n",
      "Done 10/18 at 2019-08-13 23:58:46.899122.\n",
      "Done 11/18 at 2019-08-14 00:26:35.182333.\n",
      "Done 12/18 at 2019-08-14 00:53:53.112603.\n",
      "Done 13/18 at 2019-08-14 01:20:36.839217.\n",
      "Done 14/18 at 2019-08-14 01:48:04.472977.\n",
      "Done 15/18 at 2019-08-14 02:15:24.448660.\n",
      "Done 16/18 at 2019-08-14 02:15:25.287985.\n",
      "Done 17/18 at 2019-08-14 02:15:25.730238.\n",
      "Done 18/18 at 2019-08-14 02:15:26.173697.\n",
      "CPU times: user 19h 18s, sys: 2h 33min 54s, total: 21h 34min 12s\n",
      "Wall time: 4h 22min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "small_datasets = ['vc2c', 'vc3c', 'pk']\n",
    "\n",
    "train_size = 0.5\n",
    "n_runs = 20\n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf']\n",
    "\n",
    "header = ['kernel', 'data set', 'CPU time (mean ± std)', 'GPU time (mean ± std)']\n",
    "data   = np.empty((len(kernels)*len(datasets), 4), dtype=object)\n",
    "count=0\n",
    "for dataset_name in datasets:\n",
    "    X = datasets[dataset_name]['features'].values\n",
    "    Y = datasets[dataset_name]['labels'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,train_size=train_size)  # Train/Test split\n",
    "    X_tr_norm, X_ts_norm = scale_feat(X_train, X_test, scaleType='min-max') # scaling features\n",
    "\n",
    "    for kernel in kernels:\n",
    "        temp_cpu = np.empty(n_runs)\n",
    "        temp_gpu = np.empty(n_runs)\n",
    "        for i in range(n_runs):\n",
    "            lssvm_cpu = LSSVM(gamma=1, kernel=kernel)\n",
    "            t0 = time.time()\n",
    "            lssvm_cpu.fit(X_tr_norm, y_train)\n",
    "            accuracy_score(dummie_to_multilabel(y_test), dummie_to_multilabel(lssvm_cpu.predict(X_ts_norm)))\n",
    "            t1 = time.time()\n",
    "            temp_cpu[i] = t1-t0\n",
    "            \n",
    "            lssvm_gpu = LSSVM_GPU(gamma=1, kernel=kernel)\n",
    "            t0 = time.time()\n",
    "            lssvm_gpu.fit(X_tr_norm, y_train)\n",
    "            accuracy_score(dummie_to_multilabel(y_test), dummie_to_multilabel(lssvm_gpu.predict(X_ts_norm).cpu().numpy()))\n",
    "            t1 = time.time()\n",
    "            temp_gpu[i] = t1-t0\n",
    "        \n",
    "        \n",
    "        data[count] = np.array([kernel, dataset_name, \n",
    "                                '{:.2f} ms ± {:.2f} ms'.format(np.mean(temp_cpu)*1e3, np.std(temp_cpu)*1e3), \n",
    "                                '{:.2f} ms ± {:.2f} ms'.format(np.mean(temp_gpu)*1e3, np.std(temp_gpu)*1e3)])\n",
    "        count+=1\n",
    "        print(\"Done {}/{} at {}.\".format(count, len(data), datetime.datetime.now()))\n",
    "        \n",
    "df = pd.DataFrame(data, columns=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>data set</th>\n",
       "      <th>CPU time (mean ± std)</th>\n",
       "      <th>GPU time (mean ± std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>linear</td>\n",
       "      <td>pk</td>\n",
       "      <td>7.02 ms ± 1.29 ms</td>\n",
       "      <td>34.82 ms ± 23.42 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>poly</td>\n",
       "      <td>pk</td>\n",
       "      <td>11.56 ms ± 0.53 ms</td>\n",
       "      <td>10.45 ms ± 0.25 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rbf</td>\n",
       "      <td>pk</td>\n",
       "      <td>11.05 ms ± 0.71 ms</td>\n",
       "      <td>11.01 ms ± 0.14 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>vc2c</td>\n",
       "      <td>14.30 ms ± 4.36 ms</td>\n",
       "      <td>22.71 ms ± 21.36 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poly</td>\n",
       "      <td>vc2c</td>\n",
       "      <td>23.18 ms ± 7.49 ms</td>\n",
       "      <td>17.88 ms ± 3.64 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rbf</td>\n",
       "      <td>vc2c</td>\n",
       "      <td>33.48 ms ± 18.59 ms</td>\n",
       "      <td>51.93 ms ± 41.71 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linear</td>\n",
       "      <td>vc3c</td>\n",
       "      <td>53.19 ms ± 22.06 ms</td>\n",
       "      <td>114.18 ms ± 25.69 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poly</td>\n",
       "      <td>vc3c</td>\n",
       "      <td>52.88 ms ± 14.15 ms</td>\n",
       "      <td>97.86 ms ± 28.40 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rbf</td>\n",
       "      <td>vc3c</td>\n",
       "      <td>57.54 ms ± 14.44 ms</td>\n",
       "      <td>109.17 ms ± 34.44 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>linear</td>\n",
       "      <td>wf24f</td>\n",
       "      <td>42767.05 ms ± 3093.38 ms</td>\n",
       "      <td>38998.68 ms ± 204.05 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>poly</td>\n",
       "      <td>wf24f</td>\n",
       "      <td>58120.50 ms ± 9402.79 ms</td>\n",
       "      <td>43880.65 ms ± 2061.73 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rbf</td>\n",
       "      <td>wf24f</td>\n",
       "      <td>58944.24 ms ± 15771.21 ms</td>\n",
       "      <td>45494.95 ms ± 2041.86 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>linear</td>\n",
       "      <td>wf2f</td>\n",
       "      <td>41385.23 ms ± 835.96 ms</td>\n",
       "      <td>38800.94 ms ± 55.50 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>poly</td>\n",
       "      <td>wf2f</td>\n",
       "      <td>43544.28 ms ± 644.24 ms</td>\n",
       "      <td>38837.29 ms ± 47.27 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rbf</td>\n",
       "      <td>wf2f</td>\n",
       "      <td>42032.21 ms ± 1228.18 ms</td>\n",
       "      <td>39966.47 ms ± 40.99 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>linear</td>\n",
       "      <td>wf4f</td>\n",
       "      <td>47013.78 ms ± 4669.18 ms</td>\n",
       "      <td>40283.47 ms ± 2130.28 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>poly</td>\n",
       "      <td>wf4f</td>\n",
       "      <td>44408.77 ms ± 2155.52 ms</td>\n",
       "      <td>39005.29 ms ± 394.88 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rbf</td>\n",
       "      <td>wf4f</td>\n",
       "      <td>41933.33 ms ± 589.71 ms</td>\n",
       "      <td>39963.08 ms ± 43.18 ms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    kernel data set      CPU time (mean ± std)     GPU time (mean ± std)\n",
       "15  linear       pk          7.02 ms ± 1.29 ms       34.82 ms ± 23.42 ms\n",
       "16    poly       pk         11.56 ms ± 0.53 ms        10.45 ms ± 0.25 ms\n",
       "17     rbf       pk         11.05 ms ± 0.71 ms        11.01 ms ± 0.14 ms\n",
       "0   linear     vc2c         14.30 ms ± 4.36 ms       22.71 ms ± 21.36 ms\n",
       "1     poly     vc2c         23.18 ms ± 7.49 ms        17.88 ms ± 3.64 ms\n",
       "2      rbf     vc2c        33.48 ms ± 18.59 ms       51.93 ms ± 41.71 ms\n",
       "3   linear     vc3c        53.19 ms ± 22.06 ms      114.18 ms ± 25.69 ms\n",
       "4     poly     vc3c        52.88 ms ± 14.15 ms       97.86 ms ± 28.40 ms\n",
       "5      rbf     vc3c        57.54 ms ± 14.44 ms      109.17 ms ± 34.44 ms\n",
       "6   linear    wf24f   42767.05 ms ± 3093.38 ms   38998.68 ms ± 204.05 ms\n",
       "7     poly    wf24f   58120.50 ms ± 9402.79 ms  43880.65 ms ± 2061.73 ms\n",
       "8      rbf    wf24f  58944.24 ms ± 15771.21 ms  45494.95 ms ± 2041.86 ms\n",
       "12  linear     wf2f    41385.23 ms ± 835.96 ms    38800.94 ms ± 55.50 ms\n",
       "13    poly     wf2f    43544.28 ms ± 644.24 ms    38837.29 ms ± 47.27 ms\n",
       "14     rbf     wf2f   42032.21 ms ± 1228.18 ms    39966.47 ms ± 40.99 ms\n",
       "9   linear     wf4f   47013.78 ms ± 4669.18 ms  40283.47 ms ± 2130.28 ms\n",
       "10    poly     wf4f   44408.77 ms ± 2155.52 ms   39005.29 ms ± 394.88 ms\n",
       "11     rbf     wf4f    41933.33 ms ± 589.71 ms    39963.08 ms ± 43.18 ms"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving results\n",
    "# filename = \"df.csv\"\n",
    "# df.to_csv(filename, sep='\\t', index=False)\n",
    "\n",
    "# loading results\n",
    "df = pd.read_csv(\"df.csv\", sep='\\t')\n",
    "df.sort_values(by=['data set', 'kernel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the performance on the GPU was better when the data set was big (*wf24*, *wf4f*, *wf2f*), on the small data sets the CPU version was usually faster and sometimes equivalent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
